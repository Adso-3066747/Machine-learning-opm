<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vectores en Machine Learning</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            overflow: hidden;
            height: 100vh;
            color: #ffffff;
        }

        .presentation-container {
            width: 100%;
            height: 100vh;
            position: relative;
        }

        .slide {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            justify-content: center;
            opacity: 0;
            transform: translateX(50px);
            transition: all 0.7s cubic-bezier(0.25, 0.46, 0.45, 0.94);
            padding: 40px;
        }

        .slide.active {
            opacity: 1;
            transform: translateX(0);
        }

        .slide-content {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(20px);
            border-radius: 20px;
            padding: 50px;
            max-width: 1000px;
            width: 100%;
            text-align: center;
            box-shadow: 0 25px 50px rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .slide-content.left-align {
            text-align: left;
        }

        h1 {
            font-size: 3.2em;
            margin-bottom: 20px;
            background: linear-gradient(45deg, #00d4ff, #ff00ff, #ffaa00);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            font-weight: 700;
        }

        h2 {
            font-size: 2.4em;
            color: #00d4ff;
            margin-bottom: 25px;
            font-weight: 600;
        }

        h3 {
            font-size: 1.6em;
            color: #ffaa00;
            margin-bottom: 15px;
            font-weight: 600;
        }

        p, li {
            font-size: 1.1em;
            line-height: 1.7;
            color: #e1e5e9;
            margin-bottom: 12px;
        }

        .subtitle {
            font-size: 1.3em;
            color: #a0a9b5;
            margin-bottom: 30px;
            font-weight: 300;
        }

        .code-block {
            background: rgba(0, 0, 0, 0.4);
            border-left: 4px solid #00d4ff;
            padding: 20px;
            border-radius: 10px;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.9em;
            color: #a8dadc;
            margin: 20px 0;
            text-align: left;
            overflow-x: auto;
        }

        .formula-box {
            background: linear-gradient(135deg, rgba(255, 0, 255, 0.1), rgba(0, 212, 255, 0.1));
            border: 1px solid rgba(255, 0, 255, 0.3);
            padding: 25px;
            border-radius: 15px;
            margin: 25px 0;
            font-family: 'KaTeX_Main', 'Times New Roman', serif;
            font-size: 1.2em;
            text-align: center;
        }

        .highlight-box {
            background: rgba(255, 170, 0, 0.15);
            border-left: 4px solid #ffaa00;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }

        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: 25px 0;
        }

        .three-column {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 20px;
            margin: 25px 0;
        }

        .feature-card {
            background: rgba(255, 255, 255, 0.08);
            padding: 20px;
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            transition: all 0.3s ease;
        }

        .feature-card:hover {
            background: rgba(255, 255, 255, 0.12);
            transform: translateY(-5px);
        }

        .algorithm-box {
            background: rgba(0, 212, 255, 0.1);
            border: 1px solid rgba(0, 212, 255, 0.3);
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
        }

        ul {
            text-align: left;
            padding-left: 20px;
        }

        .navigation {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 15px;
            z-index: 1000;
        }

        .nav-btn {
            padding: 15px 30px;
            background: rgba(0, 212, 255, 0.2);
            border: 2px solid rgba(0, 212, 255, 0.5);
            border-radius: 25px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            color: #00d4ff;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
        }

        .nav-btn:hover {
            background: rgba(0, 212, 255, 0.8);
            color: #1a1a2e;
            transform: translateY(-3px);
            box-shadow: 0 10px 20px rgba(0, 212, 255, 0.3);
        }

        .nav-btn:disabled {
            opacity: 0.3;
            cursor: not-allowed;
            transform: none;
        }

        .slide-counter {
            position: fixed;
            top: 30px;
            right: 30px;
            background: rgba(0, 0, 0, 0.3);
            padding: 12px 20px;
            border-radius: 25px;
            font-weight: 600;
            color: #00d4ff;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(0, 212, 255, 0.3);
        }

        .download-btn {
            position: fixed;
            top: 30px;
            left: 30px;
            padding: 12px 20px;
            background: rgba(255, 170, 0, 0.2);
            color: #ffaa00;
            border: 2px solid rgba(255, 170, 0, 0.5);
            border-radius: 25px;
            cursor: pointer;
            font-weight: 600;
            backdrop-filter: blur(10px);
            transition: all 0.3s ease;
        }

        .download-btn:hover {
            background: rgba(255, 170, 0, 0.8);
            color: #1a1a2e;
            transform: translateY(-2px);
        }

        .icon {
            font-size: 1.5em;
            margin-right: 10px;
        }

        .progress-bar {
            position: fixed;
            bottom: 0;
            left: 0;
            height: 4px;
            background: linear-gradient(90deg, #00d4ff, #ff00ff);
            transition: width 0.3s ease;
            z-index: 1001;
        }

        .math-symbol {
            color: #ff00ff;
            font-weight: bold;
            font-size: 1.1em;
        }

        .vector-notation {
            color: #00d4ff;
            font-weight: bold;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        .comparison-table th,
        .comparison-table td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .comparison-table th {
            background: rgba(0, 212, 255, 0.1);
            color: #00d4ff;
            font-weight: 600;
        }

        .center-content {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            height: 100%;
        }
    </style>
</head>
<body>
    <div class="presentation-container">
        <button class="download-btn" onclick="downloadPresentation()">üì• Descargar HTML</button>
        
        <div class="slide-counter">
            <span id="currentSlide">1</span> / <span id="totalSlides">13</span>
        </div>

        <div class="progress-bar" id="progressBar"></div>

        <!-- Slide 1: T√≠tulo -->
        <div class="slide active">
            <div class="slide-content center-content">
                <h1><span class="icon">ü§ñ</span>VECTORES EN MACHINE LEARNING</h1>
                <p class="subtitle">Fundamentos Matem√°ticos para la Inteligencia Artificial</p>
                <div class="two-column" style="margin-top: 40px;">
                    <div class="feature-card">
                        <h3>üéØ Representaci√≥n de Datos</h3>
                        <p>Cada muestra es un vector de caracter√≠sticas</p>
                    </div>
                    <div class="feature-card">
                        <h3>‚ö° Computaci√≥n Eficiente</h3>
                        <p>Operaciones matriciales optimizadas</p>
                    </div>
                </div>
                <p style="margin-top: 30px; font-size: 1.1em; color: #a0a9b5;">
                    Desarrollo Te√≥rico-Pr√°ctico ‚Ä¢ 13 Diapositivas
                </p>
            </div>
        </div>

        <!-- Slide 2: Importancia de Vectores en ML -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üöÄ ¬øPor qu√© Vectores en ML?</h2>
                <div class="two-column">
                    <div>
                        <h3>Representan Datos</h3>
                        <div class="highlight-box">
                            <p>Cada muestra es un vector de caracter√≠sticas:</p>
                            <div class="code-block">
Casa ‚Üí [√°rea, habitaciones, ba√±os, antig√ºedad]
    ‚Üí [120, 3, 2, 5]
                            </div>
                        </div>
                        
                        <h3>Modelan Relaciones</h3>
                        <p>Capturan similaridades y distancias entre datos</p>
                    </div>
                    <div>
                        <h3>Facilitan C√°lculos</h3>
                        <p>Permiten operaciones matriciales eficientes</p>
                        
                        <h3>Optimizaci√≥n</h3>
                        <div class="algorithm-box">
                            <p><strong>Los algoritmos de ML son procesos de optimizaci√≥n vectorial</strong></p>
                            <p>Navegamos en espacios de alta dimensi√≥n para encontrar par√°metros √≥ptimos</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 3: Espacios Vectoriales -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üåå Espacios Vectoriales en ML</h2>
                <div class="three-column">
                    <div class="feature-card">
                        <h3>üé® Espacio de Caracter√≠sticas</h3>
                        <p><strong>Donde viven los datos de entrada</strong></p>
                        <ul>
                            <li>Cada dimensi√≥n = una caracter√≠stica</li>
                            <li>Cada punto = una muestra</li>
                            <li>Alta dimensionalidad com√∫n</li>
                        </ul>
                    </div>
                    <div class="feature-card">
                        <h3>‚öôÔ∏è Espacio de Par√°metros</h3>
                        <p><strong>Donde viven los pesos del modelo</strong></p>
                        <ul>
                            <li>Optimizaci√≥n = navegar este espacio</li>
                            <li>Gradientes = direcciones de mejora</li>
                            <li>M√≠nimos locales/globales</li>
                        </ul>
                    </div>
                    <div class="feature-card">
                        <h3>üîÆ Espacio de Embedding</h3>
                        <p><strong>Representaciones aprendidas</strong></p>
                        <ul>
                            <li>Word embeddings</li>
                            <li>Caracter√≠sticas latentes</li>
                            <li>Dimensiones sem√°nticamente significativas</li>
                        </ul>
                    </div>
                </div>
                
                <div class="highlight-box">
                    <h3>üî• Problema: Maldici√≥n de la Dimensionalidad</h3>
                    <p>En espacios de alta dimensi√≥n, los puntos tienden a estar equidistantes, haciendo dif√≠cil la distinci√≥n entre similares y diferentes.</p>
                </div>
            </div>
        </div>

        <!-- Slide 4: Producto Escalar -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üìä Producto Escalar (Dot Product)</h2>
                <div class="formula-box">
                    <span class="vector-notation">v‚Éó ¬∑ u‚Éó</span> = <span class="math-symbol">Œ£·µ¢</span> v·µ¢u·µ¢ = v‚ÇÅu‚ÇÅ + v‚ÇÇu‚ÇÇ + ... + v‚Çôu‚Çô
                </div>
                
                <div class="two-column">
                    <div>
                        <h3>üéØ Aplicaciones en ML</h3>
                        <div class="algorithm-box">
                            <p><strong>1. Predicci√≥n Lineal:</strong></p>
                            <p><span class="vector-notation">≈∑ = w‚Éó ¬∑ x‚Éó + b</span></p>
                        </div>
                        <div class="algorithm-box">
                            <p><strong>2. Similaridad:</strong></p>
                            <p>Mide qu√© tan "parecidos" son dos vectores</p>
                        </div>
                        <div class="algorithm-box">
                            <p><strong>3. Attention (Transformers):</strong></p>
                            <p><span class="vector-notation">Attention(Q,K,V) = softmax(QK·µÄ)V</span></p>
                        </div>
                    </div>
                    <div>
                        <h3>üíª Ejemplo Pr√°ctico</h3>
                        <div class="code-block">
import numpy as np

# Datos de una casa
casa = np.array([120, 3, 2, 5])
# [√°rea, habitaciones, ba√±os, antig√ºedad]

pesos = np.array([1000, 5000, 3000, -500])
# pesos del modelo

# Predicci√≥n de precio
precio_predicho = np.dot(casa, pesos)
print(f"Precio: ${precio_predicho}")
# Resultado: $141,500
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 5: Normas Vectoriales -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üìè Normas Vectoriales</h2>
                <div class="two-column">
                    <div>
                        <h3>üî¢ Norma L2 (Euclidiana)</h3>
                        <div class="formula-box">
                            <span class="vector-notation">||v‚Éó||‚ÇÇ</span> = ‚àö(v‚ÇÅ¬≤ + v‚ÇÇ¬≤ + ... + v‚Çô¬≤)
                        </div>
                        <p><strong>Uso:</strong> Distancias, regularizaci√≥n L2, normalizaci√≥n</p>
                    </div>
                    <div>
                        <h3>üèôÔ∏è Norma L1 (Manhattan)</h3>
                        <div class="formula-box">
                            <span class="vector-notation">||v‚Éó||‚ÇÅ</span> = |v‚ÇÅ| + |v‚ÇÇ| + ... + |v‚Çô|
                        </div>
                        <p><strong>Uso:</strong> Regularizaci√≥n L1, sparsity, robustez</p>
                    </div>
                </div>
                
                <h3>üéØ Aplicaciones Principales</h3>
                <div class="three-column">
                    <div class="feature-card">
                        <h4>üõ°Ô∏è Regularizaci√≥n</h4>
                        <p>Penalizar pesos grandes para evitar overfitting</p>
                        <div class="code-block" style="font-size: 0.8em;">
L2: Œª||w||‚ÇÇ¬≤
L1: Œª||w||‚ÇÅ
                        </div>
                    </div>
                    <div class="feature-card">
                        <h4>üìê Normalizaci√≥n</h4>
                        <p>Escalar vectores a magnitud unitaria</p>
                        <div class="code-block" style="font-size: 0.8em;">
vÃÇ = v‚Éó/||v‚Éó||
                        </div>
                    </div>
                    <div class="feature-card">
                        <h4>üìä Distancias</h4>
                        <p>Medir similaridad entre puntos</p>
                        <div class="code-block" style="font-size: 0.8em;">
d(v‚Éó,u‚Éó) = ||v‚Éó-u‚Éó||
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 6: Distancias y Similaridad -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üéØ Distancias y Similaridad</h2>
                <div class="two-column">
                    <div>
                        <h3>üìê Distancia Euclidiana</h3>
                        <div class="formula-box">
                            d(v‚Éó, u‚Éó) = <span class="vector-notation">||v‚Éó - u‚Éó||‚ÇÇ</span>
                        </div>
                        <p>Distancia "directa" en el espacio</p>
                        
                        <h3>üß≠ Similaridad Coseno</h3>
                        <div class="formula-box">
                            cos_sim(v‚Éó, u‚Éó) = <span class="math-symbol">(v‚Éó ¬∑ u‚Éó) / (||v‚Éó|| ||u‚Éó||)</span>
                        </div>
                        <p>Mide el √°ngulo entre vectores</p>
                    </div>
                    <div>
                        <h3>üöÄ Aplicaciones</h3>
                        <div class="algorithm-box">
                            <h4>K-Nearest Neighbors</h4>
                            <p>Encontrar los k vecinos m√°s cercanos</p>
                        </div>
                        <div class="algorithm-box">
                            <h4>Clustering</h4>
                            <p>Agrupar puntos similares (K-means, etc.)</p>
                        </div>
                        <div class="algorithm-box">
                            <h4>Sistemas de Recomendaci√≥n</h4>
                            <p>Similaridad entre usuarios/items</p>
                        </div>
                    </div>
                </div>
                
                <div class="highlight-box">
                    <p><strong>üí° Insight:</strong> La similaridad coseno es independiente de la magnitud, solo considera la direcci√≥n. Ideal para textos y vectores de diferentes escalas.</p>
                </div>
            </div>
        </div>

        <!-- Slide 7: Regresi√≥n Lineal Vectorial -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üìà Regresi√≥n Lineal Vectorial</h2>
                <div class="two-column">
                    <div>
                        <h3>üìã Formulaci√≥n</h3>
                        <div class="formula-box">
                            <p><strong>Hip√≥tesis:</strong> h(x‚Éó) = <span class="vector-notation">w‚Éó·µÄx‚Éó</span> + b</p>
                            <p><strong>Costo:</strong> J(w‚Éó) = <span class="math-symbol">¬Ωm</span> <span class="vector-notation">||Xw‚Éó - y‚Éó||¬≤</span></p>
                            <p><strong>Gradiente:</strong> ‚àáJ(w‚Éó) = <span class="math-symbol">1/m</span> <span class="vector-notation">X·µÄ(Xw‚Éó - y‚Éó)</span></p>
                        </div>
                        
                        <div class="algorithm-box">
                            <h4>üîÑ Gradient Descent</h4>
                            <p><span class="vector-notation">w‚Éó‚Çú‚Çä‚ÇÅ = w‚Éó‚Çú - Œ±‚àáJ(w‚Éó‚Çú)</span></p>
                        </div>
                    </div>
                    <div>
                        <h3>üíª Implementaci√≥n</h3>
                        <div class="code-block" style="font-size: 0.75em;">
class LinearRegression:
    def __init__(self, lr=0.01):
        self.lr = lr
        self.weights = None
        self.bias = 0
    
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        
        for i in range(1000):
            # Predicci√≥n vectorial
            y_pred = np.dot(X, self.weights) + self.bias
            
            # Gradientes vectoriales
            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))
            db = (1/n_samples) * np.sum(y_pred - y)
            
            # Actualizaci√≥n
            self.weights -= self.lr * dw
            self.bias -= self.lr * db
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 8: Word Embeddings -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üî§ Word Embeddings</h2>
                <div class="two-column">
                    <div>
                        <h3>üé® Concepto</h3>
                        <p>Representar palabras como vectores densos donde <strong>palabras similares tienen vectores cercanos</strong></p>
                        
                        <div class="algorithm-box">
                            <h4>Word2Vec</h4>
                            <p>Aprende embeddings basados en contexto</p>
                        </div>
                        
                        <div class="highlight-box">
                            <h4>üîÆ Operaciones Sem√°nticas</h4>
                            <div class="formula-box">
                                <span class="vector-notation">king - man + woman ‚âà queen</span><br>
                                <span class="vector-notation">Paris - France + Italy ‚âà Rome</span>
                            </div>
                        </div>
                    </div>
                    <div>
                        <h3>üíª Ejemplo Conceptual</h3>
                        <div class="code-block" style="font-size: 0.8em;">
# Vectores de ejemplo (dimensi√≥n 5)
king = np.array([0.2, 0.8, 0.3, -0.1, 0.9])
queen = np.array([0.1, 0.7, 0.4, -0.2, 0.8])
man = np.array([0.5, 0.1, 0.2, 0.8, 0.3])
woman = np.array([0.3, 0.2, 0.1, 0.7, 0.4])

# Aritm√©tica vectorial sem√°ntica
result = king - man + woman

# Verificar similaridad
cosine_sim = np.dot(result, queen) / (
    np.linalg.norm(result) * np.linalg.norm(queen)
)
print(f"Similaridad con queen: {cosine_sim:.3f}")
                        </div>
                        
                        <h3>üéØ Aplicaciones</h3>
                        <ul>
                            <li>Procesamiento de lenguaje natural</li>
                            <li>Sistemas de recomendaci√≥n</li>
                            <li>An√°lisis de sentimientos</li>
                            <li>Traducci√≥n autom√°tica</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 9: Optimizaci√≥n Vectorial -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>‚ö° Optimizaci√≥n Vectorial</h2>
                <div class="three-column">
                    <div class="feature-card">
                        <h3>üéØ Gradient Descent</h3>
                        <div class="formula-box" style="font-size: 1em;">
                            <span class="vector-notation">w‚Éó‚Çú‚Çä‚ÇÅ = w‚Éó‚Çú - Œ±‚àáJ(w‚Éó‚Çú)</span>
                        </div>
                        <p><strong>Variantes:</strong></p>
                        <ul style="font-size: 0.9em;">
                            <li><strong>Batch GD:</strong> Todo el dataset</li>
                            <li><strong>SGD:</strong> Una muestra aleatoria</li>
                            <li><strong>Mini-batch:</strong> Subconjunto peque√±o</li>
                        </ul>
                    </div>
                    
                    <div class="feature-card">
                        <h3>üöÄ Momentum</h3>
                        <p>Acelera usando "velocidad":</p>
                        <div class="formula-box" style="font-size: 0.9em;">
                            <span class="vector-notation">v‚Éó‚Çú‚Çä‚ÇÅ = Œ≤v‚Éó‚Çú + Œ±‚àáJ(w‚Éó‚Çú)</span><br>
                            <span class="vector-notation">w‚Éó‚Çú‚Çä‚ÇÅ = w‚Éó‚Çú - v‚Éó‚Çú‚Çä‚ÇÅ</span>
                        </div>
                        <p style="font-size: 0.9em;">Ayuda a superar m√≠nimos locales</p>
                    </div>
                    
                    <div class="feature-card">
                        <h3>üéõÔ∏è Adam</h3>
                        <p>Combina momentum + adaptaci√≥n:</p>
                        <div class="formula-box" style="font-size: 0.8em;">
                            <span class="vector-notation">m‚Éó‚Çú = Œ≤‚ÇÅm‚Éó‚Çú‚Çã‚ÇÅ + (1-Œ≤‚ÇÅ)‚àáJ</span><br>
                            <span class="vector-notation">v‚Éó‚Çú = Œ≤‚ÇÇv‚Éó‚Çú‚Çã‚ÇÅ + (1-Œ≤‚ÇÇ)(‚àáJ)¬≤</span><br>
                            <span class="vector-notation">w‚Éó‚Çú‚Çä‚ÇÅ = w‚Éó‚Çú - Œ±(m‚Éó‚Çú/‚àö(v‚Éó‚Çú + Œµ))</span>
                        </div>
                        <p style="font-size: 0.9em;">Optimizador m√°s popular en deep learning</p>
                    </div>
                </div>
                
                <div class="highlight-box">
                    <h3>üîë Principio Clave</h3>
                    <p>Todos estos algoritmos navegan en el espacio de par√°metros usando informaci√≥n vectorial (gradientes) para encontrar configuraciones que minimizen la funci√≥n de p√©rdida.</p>
                </div>
            </div>
        </div>

        <!-- Slide 10: Transformaciones -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üîÑ Transformaciones Vectoriales</h2>
                <div class="two-column">
                    <div>
                        <h3>üìä Normalizaci√≥n</h3>
                        <div class="algorithm-box">
                            <h4>Min-Max Scaling</h4>
                            <div class="formula-box" style="font-size: 0.9em;">
                                x'·µ¢ = (x·µ¢ - min(x‚Éó))/(max(x‚Éó) - min(x‚Éó))
                            </div>
                        </div>
                        
                        <div class="algorithm-box">
                            <h4>Z-Score Normalization</h4>
                            <div class="formula-box" style="font-size: 0.9em;">
                                x'·µ¢ = (x·µ¢ - Œº)/œÉ
                            </div>
                        </div>
                    </div>
                    <div>
                        <h3>üìâ Reducci√≥n de Dimensionalidad</h3>
                        <div class="algorithm-box">
                            <h4>PCA (Principal Component Analysis)</h4>
                            <p style="font-size: 0.9em;">Encuentra direcciones de m√°xima varianza:</p>
                            <ol style="font-size: 0.8em;">
                                <li>Centrar: XÃÉ = X - Œº</li>
                                <li>Covarianza: C = (1/n)XÃÉ·µÄXÃÉ</li>
                                <li>Eigendecomposici√≥n: C = PŒõP·µÄ</li>
                                <li>Proyecci√≥n: Y = XP</li>
                            </ol>
                        </div>
                        
                        <div class="code-block" style="font-size: 0.7em;">
def normalize_features(X):
    # Z-score normalization
    mean = np.mean(X, axis=0)
    std = np.std(X, axis=0)
    return (X - mean) / std

X_norm = normalize_features(X_train)
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 11: Casos Pr√°cticos - Recomendaci√≥n -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üé¨ Caso Pr√°ctico: Sistema de Recomendaci√≥n</h2>
                <div class="two-column">
                    <div>
                        <h3>üéØ Concepto</h3>
                        <p>Usar <strong>similaridad coseno</strong> entre vectores de usuario para encontrar personas con gustos similares</p>
                        
                        <div class="highlight-box">
                            <h4>üë• Collaborative Filtering</h4>
                            <p>"Los usuarios similares a ti tambi√©n disfrutaron..."</p>
                        </div>
                        
                        <div class="algorithm-box">
                            <h4>üî¢ Matriz Usuario-Item</h4>
                            <table class="comparison-table" style="font-size: 0.8em;">
                                <tr><th></th><th>Film A</th><th>Film B</th><th>Film C</th></tr>
                                <tr><td>User 1</td><td>5</td><td>4</td><td>0</td></tr>
                                <tr><td>User 2</td><td>0</td><td>3</td><td>4</td></tr>
                                <tr><td>User 3</td><td>4</td><td>0</td><td>5</td></tr>
                            </table>
                        </div>
                    </div>
                    <div>
                        <h3>üíª Implementaci√≥n</h3>
                        <div class="code-block" style="font-size: 0.65em;">
class RecommenderSystem:
    def __init__(self):
        self.user_vectors = None
    
    def fit(self, user_item_matrix):
        self.user_vectors = user_item_matrix
    
    def recommend(self, user_id, n_rec=5):
        user_vector = self.user_vectors[user_id]
        
        # Calcular similaridades coseno
        similarities = cosine_similarity(
            [user_vector], self.user_vectors
        )[0]
        
        # Usuarios similares (top 5)
        similar_users = np.argsort(similarities)[-6:-1]
        
        # Recomendar items populares
        recommendations = []
        for similar_user in similar_users:
            user_items = self.user_vectors[similar_user]
            recs = np.where(user_items > 0)[0]
            recommendations.extend(recs)
        
        return list(set(recommendations))[:n_rec]

# Uso
recommender = RecommenderSystem()
recommender.fit(ratings_matrix)
recs = recommender.recommend(user_id=0)
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 12: Deep Learning y Vectores -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üß† Deep Learning y Vectores</h2>
                <div class="three-column">
                    <div class="feature-card">
                        <h3>üîç CNNs</h3>
                        <p><strong>Filtros:</strong> Vectores que se convolucionan con la entrada</p>
                        <p><strong>Feature maps:</strong> Representaciones vectoriales de caracter√≠sticas detectadas</p>
                        <div class="code-block" style="font-size: 0.7em;">
# Convoluci√≥n = producto escalar
output[i,j] = Œ£ filter * patch[i,j]
                        </div>
                    </div>
                    
                    <div class="feature-card">
                        <h3>üîÑ RNNs</h3>
                        <p><strong>Estados ocultos:</strong> Vectores que mantienen memoria temporal</p>
                        <p><strong>Embeddings:</strong> Representaciones densas de tokens</p>
                        <div class="code-block" style="font-size: 0.7em;">
h_t = tanh(W_h h_{t-1} + W_x x_t + b)
                        </div>
                    </div>
                    
                    <div class="feature-card">
                        <h3>üéØ Transformers</h3>
                        <p><strong>Query, Key, Value:</strong> Vectores que determinan atenci√≥n</p>
                        <p><strong>Multi-head attention:</strong> M√∫ltiples espacios de atenci√≥n</p>
                        <div class="code-block" style="font-size: 0.7em;">
Attention = softmax(QK^T/‚àöd_k)V
                        </div>
                    </div>
                </div>
                
                <div class="highlight-box">
                    <h3>üîë Attention Mechanism</h3>
                    <div class="code-block" style="font-size: 0.8em;">
def scaled_dot_product_attention(Q, K, V):
    """
    Q: Query vectors [batch, seq_len, d_k]
    K: Key vectors [batch, seq_len, d_k]  
    V: Value vectors [batch, seq_len, d_v]
    """
    d_k = Q.shape[-1]
    
    # Compute attention scores (productos escalares)
    scores = np.matmul(Q, K.transpose(-2, -1)) / np.sqrt(d_k)
    
    # Apply softmax
    attention_weights = softmax(scores, axis=-1)
    
    # Apply attention to values
    output = np.matmul(attention_weights, V)
    
    return output, attention_weights
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 13: Resumen y Conclusiones -->
        <div class="slide">
            <div class="slide-content left-align">
                <h2>üéØ Conclusiones Clave</h2>
                
                <div class="two-column">
                    <div>
                        <h3>üöÄ Principios Fundamentales</h3>
                        <div class="feature-card">
                            <ul>
                                <li><strong>Todo es un vector:</strong> Datos, par√°metros, gradientes</li>
                                <li><strong>Operaciones matriciales:</strong> Base de eficiencia computacional</li>
                                <li><strong>Espacios de alta dimensi√≥n:</strong> Donde viven los datos reales</li>
                                <li><strong>Similaridades y distancias:</strong> Core de muchos algoritmos</li>
                                <li><strong>Optimizaci√≥n:</strong> Navegaci√≥n en espacios de par√°metros</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div>
                        <h3>‚ö° Mejores Pr√°cticas</h3>
                        <div class="algorithm-box">
                            <ul>
                                <li>‚úÖ <strong>Normalizar caracter√≠sticas</strong> para estabilidad num√©rica</li>
                                <li>‚úÖ <strong>Usar operaciones vectorizadas</strong> para eficiencia</li>
                                <li>‚úÖ <strong>Entender la geometr√≠a</strong> de los datos</li>
                                <li>‚úÖ <strong>Aplicar regularizaci√≥n</strong> para evitar overfitting</li>
                                <li>‚úÖ <strong>Visualizar en menor dimensi√≥n</strong> cuando sea posible</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="highlight-box">
                    <h3>üé® El Arte del Machine Learning</h3>
                    <p style="font-size: 1.2em; text-align: center;">
                        <strong>Los vectores no son solo herramientas matem√°ticas en ML; son el lenguaje fundamental que permite a las m√°quinas aprender patrones complejos de los datos.</strong>
                    </p>
                </div>
                
                <div class="formula-box" style="margin-top: 30px;">
                    <h3 style="color: #00d4ff;">üîÆ Desde datos hasta inteligencia:</h3>
                    <p style="font-size: 1.1em;">
                        <span class="vector-notation">Datos</span> ‚Üí <span class="math-symbol">Vectores</span> ‚Üí <span class="vector-notation">Operaciones</span> ‚Üí <span class="math-symbol">Optimizaci√≥n</span> ‚Üí <span class="vector-notation">Inteligencia Artificial</span>
                    </p>
                </div>
                
                <div style="text-align: center; margin-top: 40px;">
                    <h2 style="color: #ffaa00;">¬°Gracias por su atenci√≥n! üöÄ</h2>
                    <p style="color: #a0a9b5;">¬øPreguntas sobre vectores en ML?</p>
                </div>
            </div>
        </div>

        <div class="navigation">
            <button class="nav-btn" id="prevBtn" onclick="changeSlide(-1)">‚¨Ö Anterior</button>
            <button class="nav-btn" id="nextBtn" onclick="changeSlide(1)">Siguiente ‚û°</button>
        </div>
    </div>

    <script>
        let currentSlideIndex = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;
        
        document.getElementById('totalSlides').textContent = totalSlides;
        
        function updateProgressBar() {
            const progress = ((currentSlideIndex + 1) / totalSlides) * 100;
            document.getElementById('progressBar').style.width = progress + '%';
        }
        
        function showSlide(index) {
            slides.forEach(slide => slide.classList.remove('active'));
            slides[index].classList.add('active');
            
            document.getElementById('currentSlide').textContent = index + 1;
            updateProgressBar();
            
            // Update navigation buttons
            document.getElementById('prevBtn').disabled = index === 0;
            document.getElementById('nextBtn').disabled = index === totalSlides - 1;
        }
        
        function changeSlide(direction) {
            const newIndex = currentSlideIndex + direction;
            if (newIndex >= 0 && newIndex < totalSlides) {
                currentSlideIndex = newIndex;
                showSlide(currentSlideIndex);
            }
        }
        
        // Keyboard navigation
        document.addEventListener('keydown', function(e) {
            if (e.key === 'ArrowRight' || e.key === ' ') {
                e.preventDefault();
                changeSlide(1);
            } else if (e.key === 'ArrowLeft') {
                e.preventDefault();
                changeSlide(-1);
            } else if (e.key === 'Home') {
                e.preventDefault();
                currentSlideIndex = 0;
                showSlide(0);
            } else if (e.key === 'End') {
                e.preventDefault();
                currentSlideIndex = totalSlides - 1;
                showSlide(totalSlides - 1);
            }
        });
        
        // Touch/swipe support for mobile
        let touchStartX = 0;
        let touchEndX = 0;
        
        document.addEventListener('touchstart', function(e) {
            touchStartX = e.changedTouches[0].screenX;
        });
        
        document.addEventListener('touchend', function(e) {
            touchEndX = e.changedTouches[0].screenX;
            handleSwipe();
        });
        
        function handleSwipe() {
            const swipeThreshold = 50;
            const diff = touchStartX - touchEndX;
            
            if (Math.abs(diff) > swipeThreshold) {
                if (diff > 0) {
                    // Swipe left - next slide
                    changeSlide(1);
                } else {
                    // Swipe right - previous slide
                    changeSlide(-1);
                }
            }
        }
        
        function downloadPresentation() {
            const htmlContent = document.documentElement.outerHTML;
            const blob = new Blob([htmlContent], { type: 'text/html' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'Vectores-en-Machine-Learning.html';
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }
        
        // Initialize
        showSlide(0);
        
        // Preload next slide for smoother transitions
        function preloadSlide(index) {
            if (index >= 0 && index < totalSlides) {
                slides[index].style.transform = 'translateX(0)';
            }
        }
        
        // Auto-save progress in sessionStorage (not localStorage due to restrictions)
        function saveProgress() {
            try {
                sessionStorage.setItem('ml-vectors-slide', currentSlideIndex.toString());
            } catch(e) {
                // Silently fail if sessionStorage not available
            }
        }
        
        function loadProgress() {
            try {
                const saved = sessionStorage.getItem('ml-vectors-slide');
                if (saved !== null) {
                    const slideIndex = parseInt(saved);
                    if (slideIndex >= 0 && slideIndex < totalSlides) {
                        currentSlideIndex = slideIndex;
                        showSlide(currentSlideIndex);
                    }
                }
            } catch(e) {
                // Silently fail if sessionStorage not available
            }
        }
        
        // Load progress on page load
        window.addEventListener('load', loadProgress);
        
        // Save progress when changing slides
        const originalChangeSlide = changeSlide;
        changeSlide = function(direction) {
            originalChangeSlide(direction);
            saveProgress();
        };
    </script>
</body>
</html>